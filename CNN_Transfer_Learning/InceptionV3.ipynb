{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 42196,
     "status": "ok",
     "timestamp": 1561908311874,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "ndOM0KpAlfxM",
    "outputId": "cde6bdae-c655-4e21-8d62-705af6d7d341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (5.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.14.5)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmH50ibX9KQ7"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.backend import set_session\n",
    "import tensorflow as tf\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)sess = tf.Session(config=config)set_session(sess)\n",
    "# sess = tf.Session(config=config)\n",
    "# set_session(sess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as ktf\n",
    "\n",
    "\n",
    "def get_session(gpu_fraction=0.9):\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction,\n",
    "                                allow_growth=True)\n",
    "    return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "ktf.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5056,
     "status": "ok",
     "timestamp": 1561919672504,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "tk28xpFxnAqa",
    "outputId": "526d266c-5750-42ff-af3b-67bb20b4596c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "#from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "#from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam as Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7681,
     "status": "error",
     "timestamp": 1561919675705,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "2oj9WnXOlt_C",
    "outputId": "36f3e405-6019-4ddb-a106-d898a5284ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_model= InceptionV3(include_top=False, weights='../inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', input_shape=(299,299,3))\n",
    "# model=load_model(\"InceptionV34.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_ykdl9qmEDo"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from tensorflow.keras.layers import Dropout\n",
    "model= Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "#model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_80 (Batc (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_v1_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_77 (Batc (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_81 (Batc (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_78 (Batc (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_79 (Batc (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_82 (Batc (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_83 (Batc (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_76 (Batc (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_84 (Batc (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_v1_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_v1_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_89 (Batc (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_v1_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_86 (Batc (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_90 (Batc (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_87 (Batc (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_88 (Batc (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_91 (Batc (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_92 (Batc (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_85 (Batc (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_v1_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_93 (Batc (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_v1_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_v1_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 6, 6, 64)          1179712   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 23,019,681\n",
      "Trainable params: 22,985,249\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2B5VHMq-mb_F"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(rescale = 1./255,\n",
    "                                     rotation_range=10,  \n",
    "                                     zoom_range = 0.1, \n",
    "                                     width_shift_range=0.2,  height_shift_range=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57298,
     "status": "ok",
     "timestamp": 1561908385668,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "DJ7QCh67mfJF",
    "outputId": "8c5292e9-54b8-48a6-fb2d-0c233211a1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 948603 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data= train_generator.flow_from_directory(\n",
    "                                                batch_size=256,directory=\"/raid/Data/Master_Dataset/elvin/final_mix/train/\",\n",
    "                                                shuffle=True,class_mode=\"binary\",target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5GFfxtomjhZ"
   },
   "outputs": [],
   "source": [
    "test_generator=ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56449,
     "status": "ok",
     "timestamp": 1561908388015,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "nStpDSfDmm1N",
    "outputId": "19aaeda6-0f55-4855-b8b3-4fe268fa0cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 518144 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data= test_generator.flow_from_directory(\n",
    "                                              directory=\"/raid/Data/Master_Dataset/elvin/final_mix/validation/\",\n",
    "                                              shuffle=True,batch_size=256,class_mode=\"binary\",target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRDW75QQmr2k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=.5, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0A_7voRBvZa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "\n",
    "# # Save the model with best weights\n",
    "# checkpointer = ModelCheckpoint('Xceptionbestweights1.hdf5', verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5166449,
     "status": "ok",
     "timestamp": 1561915317414,
     "user": {
      "displayName": "new guy",
      "photoUrl": "",
      "userId": "03120160726989926836"
     },
     "user_tz": -330
    },
    "id": "g8AZIYZ2myZr",
    "outputId": "27d218e5-c794-4705-b86f-df11b40eb0dc"
   },
   "outputs": [],
   "source": [
    "# parallel_model = multi_gpu_model(model, gpus=3)\n",
    "# parallel_model.compile(loss='binary_crossentropy',\n",
    "#                            optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
    "# #model.compile(optimizer=Adam(lr=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "# parallel_model.fit_generator(generator=train_data,\n",
    "#                             steps_per_epoch=train_data.samples//train_data.batch_size,\n",
    "#                             validation_data=val_data,\n",
    "#                             verbose=1,\n",
    "#                             validation_steps=val_data.samples//val_data.batch_size,\n",
    "#                             epochs=3,callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history,epoch):\n",
    "    # plot loss\n",
    "    pyplot.subplot(121)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    pyplot.ylabel('Loss')\n",
    "    pyplot.xlabel('Epochs')\n",
    "\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(122)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "    pyplot.ylabel('Accuracy')\n",
    "    pyplot.xlabel('Epochs')\n",
    "\n",
    "    pyplot.subplots_adjust(top=0.92, bottom=0.2, left=0.0, right=2.5, hspace=0.25,\n",
    "                    wspace=0.25)\n",
    "    pyplot.show()    \n",
    "\n",
    "\n",
    "    #     pyplot.subplot(213)\n",
    "    # \tpyplot.title('Classification Accuracy')\n",
    "    # \tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    # \tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename +'InceptionNewAdam'+str(epoch)+ '_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import multi_gpu_model\n",
    "# #for y in [1,2,3,4,5,6,7,9,14]:\n",
    "# for y in [2,4,6]:\n",
    "#     try:\n",
    "#         location=\"BestWeights_epoch\"+str(y)+ \".hdf5\"\n",
    "#         checkpointer = ModelCheckpoint(location, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "#         final_location=[]\n",
    "#         location=[]\n",
    "#         model= Sequential()\n",
    "#         model.add(base_model)\n",
    "#         model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#         #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "#         #model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#         model.add(Dropout(0.40))\n",
    "#         model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#         #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "#         model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#         model.add(Dropout(0.40))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(512,activation='relu'))\n",
    "#         model.add(Dropout(0.4))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model.add(Conv2D(512, (3, 3), activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "#         #parallel_model = multi_gpu_model(model, gpus=2)\n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                                optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
    "#     #model.compile(optimizer=Adam(lr=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "#         history_model=model.fit_generator(generator=train_data,\n",
    "#                                 steps_per_epoch=train_data.samples//train_data.batch_size,\n",
    "#                                 validation_data=val_data,\n",
    "#                                 verbose=1,\n",
    "#                                 validation_steps=val_data.samples//val_data.batch_size,\n",
    "#                                 epochs=y,callbacks=[learning_rate_reduction,es,checkpointer])\n",
    "#         model.save(\"InceptionV3\"+str(y)+\".hdf5\")\n",
    "#         summarize_diagnostics(history_model,y)\n",
    "#         loss=history_model.history['loss']\n",
    "#         acc=history_model.history['acc']\n",
    "#         valacc=history_model.history['val_acc']\n",
    "#         valloss=history_model.history['val_loss']\n",
    "#         location = [y,loss,acc,valacc, valloss]\n",
    "#         final_location.append(location)\n",
    "#         save1 = pd.DataFrame(final_location,columns=['epochs','loss','acc','valacc','valloss'])\n",
    "#         save1.to_csv('InceptionV3'+str(y)+'.csv')\n",
    "#     except Exception as e: \n",
    "#         print(e)\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "2024/2024 [==============================] - 2667s 1s/step - loss: 0.3353 - acc: 0.8527\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85271, saving model to BestWeights_epoch2.hdf5\n",
      "3706/3706 [==============================] - 22312s 6s/step - loss: 0.2178 - acc: 0.9025 - val_loss: 0.3353 - val_acc: 0.8527\n",
      "Epoch 2/2\n",
      "2024/2024 [==============================] - 2382s 1s/step - loss: 0.7137 - acc: 0.7810\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.85271\n",
      "3706/3706 [==============================] - 22258s 6s/step - loss: 0.0940 - acc: 0.9631 - val_loss: 0.7137 - val_acc: 0.7810\n",
      "Epoch 1/4\n",
      "2024/2024 [==============================] - 2335s 1s/step - loss: 1.7733 - acc: 0.6995\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69949, saving model to BestWeights_epoch4.hdf5\n",
      "3706/3706 [==============================] - 19461s 5s/step - loss: 0.0766 - acc: 0.9707 - val_loss: 1.7733 - val_acc: 0.6995\n",
      "Epoch 2/4\n",
      "2024/2024 [==============================] - 2294s 1s/step - loss: 0.4004 - acc: 0.8821\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69949 to 0.88214, saving model to BestWeights_epoch4.hdf5\n",
      "3706/3706 [==============================] - 19325s 5s/step - loss: 0.0575 - acc: 0.9781 - val_loss: 0.4004 - val_acc: 0.8821\n",
      "Epoch 3/4\n",
      "2024/2024 [==============================] - 2443s 1s/step - loss: 1.4159 - acc: 0.6952\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88214\n",
      "3706/3706 [==============================] - 19818s 5s/step - loss: 0.0494 - acc: 0.9813 - val_loss: 1.4159 - val_acc: 0.6952\n",
      "Epoch 4/4\n",
      "2024/2024 [==============================] - 2670s 1s/step - loss: 0.4945 - acc: 0.8724\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88214\n",
      "3706/3706 [==============================] - 23011s 6s/step - loss: 0.0437 - acc: 0.9835 - val_loss: 0.4945 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "2024/2024 [==============================] - 2682s 1s/step - loss: 0.4777 - acc: 0.8891\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88907, saving model to BestWeights_epoch6.hdf5\n",
      "3706/3706 [==============================] - 23674s 6s/step - loss: 0.0393 - acc: 0.9856 - val_loss: 0.4777 - val_acc: 0.8891\n",
      "Epoch 2/6\n",
      "1168/3706 [========>.....................] - ETA: 3:57:41 - loss: 0.0337 - acc: 0.9877"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "#for y in [1,2,3,4,5,6,7,9,14]:\n",
    "for y in [2,4,6]:\n",
    "    try:\n",
    "        location=\"BestWeights_epoch\"+str(y)+ \".hdf5\"\n",
    "        checkpointer = ModelCheckpoint(location, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "        final_location=[]\n",
    "        location=[]\n",
    "        model= Sequential()\n",
    "        model.add(base_model)\n",
    "        model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "        #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "        #model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "        model.add(Dropout(0.40))\n",
    "        model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "        #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "        model.add(Dropout(0.40))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    # model.add(Conv2D(512, (3, 3), activation = 'relu'))\n",
    "\n",
    "\n",
    "\n",
    "        parallel_model = multi_gpu_model(model, gpus=2)\n",
    "        parallel_model.compile(loss='binary_crossentropy',\n",
    "                               optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
    "    #model.compile(optimizer=Adam(lr=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "        history_model=parallel_model.fit_generator(generator=train_data,\n",
    "                                steps_per_epoch=train_data.samples//train_data.batch_size,\n",
    "                                validation_data=val_data,\n",
    "                                verbose=1,\n",
    "                                validation_steps=val_data.samples//val_data.batch_size,\n",
    "                                epochs=y,callbacks=[learning_rate_reduction,es,checkpointer])\n",
    "        model.save(\"InceptionV3\"+str(y)+\".hdf5\")\n",
    "        summarize_diagnostics(history_model,y)\n",
    "        loss=history_model.history['loss']\n",
    "        acc=history_model.history['acc']\n",
    "        valacc=history_model.history['val_acc']\n",
    "        valloss=history_model.history['val_loss']\n",
    "        location = [y,loss,acc,valacc, valloss]\n",
    "        final_location.append(location)\n",
    "        save1 = pd.DataFrame(final_location,columns=['epochs','loss','acc','valacc','valloss'])\n",
    "        save1.to_csv('InceptionV3'+str(y)+'.csv')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/6\n",
      "2024/2024 [==============================] - 2221s 1s/step - loss: 0.3579 - acc: 0.8978\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89779, saving model to BestWeights_epoch6.hdf5\n",
      "3706/3706 [==============================] - 20012s 5s/step - loss: 0.0387 - acc: 0.9856 - val_loss: 0.3579 - val_acc: 0.8978\n",
      "Epoch 2/6\n",
      "2024/2024 [==============================] - 2218s 1s/step - loss: 0.5214 - acc: 0.8852\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89779\n",
      "3706/3706 [==============================] - 19157s 5s/step - loss: 0.0342 - acc: 0.9872 - val_loss: 0.5214 - val_acc: 0.8852\n",
      "Epoch 3/6\n",
      "2024/2024 [==============================] - 2265s 1s/step - loss: 0.4502 - acc: 0.8858\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89779\n",
      "3706/3706 [==============================] - 19257s 5s/step - loss: 0.0317 - acc: 0.9884 - val_loss: 0.4502 - val_acc: 0.8858\n",
      "Epoch 4/6\n",
      "2024/2024 [==============================] - 2379s 1s/step - loss: 0.3989 - acc: 0.8989\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89779 to 0.89888, saving model to BestWeights_epoch6.hdf5\n",
      "3706/3706 [==============================] - 20696s 6s/step - loss: 0.0182 - acc: 0.9933 - val_loss: 0.3989 - val_acc: 0.8989\n",
      "Epoch 5/6\n",
      "2024/2024 [==============================] - 2368s 1s/step - loss: 0.4286 - acc: 0.9009\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.89888 to 0.90093, saving model to BestWeights_epoch6.hdf5\n",
      "3706/3706 [==============================] - 20445s 6s/step - loss: 0.0156 - acc: 0.9944 - val_loss: 0.4286 - val_acc: 0.9009\n",
      "Epoch 6/6\n",
      "2024/2024 [==============================] - 2346s 1s/step - loss: 0.3974 - acc: 0.9071\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90093 to 0.90710, saving model to BestWeights_epoch6.hdf5\n",
      "3706/3706 [==============================] - 20347s 5s/step - loss: 0.0138 - acc: 0.9950 - val_loss: 0.3974 - val_acc: 0.9071\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "#for y in [1,2,3,4,5,6,7,9,14]:\n",
    "for y in [6]:\n",
    "    try:\n",
    "        location=\"BestWeights_epoch\"+str(y)+ \".hdf5\"\n",
    "        checkpointer = ModelCheckpoint(location, monitor='val_acc', verbose=1, save_best_only=True, mode='max')    \n",
    "        final_location=[]\n",
    "        location=[]\n",
    "#         model= Sequential()\n",
    "#         model.add(base_model)\n",
    "#         model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#         #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "#         #model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#         model.add(Dropout(0.40))\n",
    "#         model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "#         #model.add(BatchNormalization(axis=-1, momentum=0.1, epsilon=1e-04))\n",
    "#         model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#         model.add(Dropout(0.40))\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(512,activation='relu'))\n",
    "#         model.add(Dropout(0.4))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "    # model.add(Conv2D(512, (3, 3), activation = 'relu'))\n",
    "\n",
    "        model=load_model(\"InceptionV34.hdf5\")\n",
    "\n",
    "        parallel_model = multi_gpu_model(model, gpus=2)\n",
    "        parallel_model.compile(loss='binary_crossentropy',\n",
    "                               optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n",
    "    #model.compile(optimizer=Adam(lr=0.001),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "        history_model=parallel_model.fit_generator(generator=train_data,\n",
    "                                steps_per_epoch=train_data.samples//train_data.batch_size,\n",
    "                                validation_data=val_data,\n",
    "                                verbose=1,\n",
    "                                validation_steps=val_data.samples//val_data.batch_size,\n",
    "                                epochs=y,callbacks=[learning_rate_reduction,es,checkpointer])\n",
    "        model.save(\"InceptionV3\"+str(y)+\".hdf5\")\n",
    "        summarize_diagnostics(history_model,y)\n",
    "        loss=history_model.history['loss']\n",
    "        acc=history_model.history['acc']\n",
    "        valacc=history_model.history['val_acc']\n",
    "        valloss=history_model.history['val_loss']\n",
    "        location = [y,loss,acc,valacc, valloss]\n",
    "        final_location.append(location)\n",
    "        save1 = pd.DataFrame(final_location,columns=['epochs','loss','acc','valacc','valloss'])\n",
    "        save1.to_csv('InceptionV3'+str(y)+'.csv')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InceptionV3Own1Arch2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
